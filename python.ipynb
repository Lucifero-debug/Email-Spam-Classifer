{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import optuna\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv('spam.csv')\n",
    "df=df.loc[:,['v1','v2']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_Stem=PorterStemmer()\n",
    "def streming(content):\n",
    "    stremed_content=re.sub('[^a-zA-Z]',' ',content)\n",
    "    stremed_content=stremed_content.lower()\n",
    "    stremed_content=stremed_content.split()\n",
    "    stremed_content=[port_Stem.stem(word) for word in stremed_content if not word in stopwords.words('english')]\n",
    "    stremed_content=' '.join(stremed_content)\n",
    "    return stremed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v2']=df['v2'].apply(streming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['v1']=le.fit_transform(df.loc[:,'v1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entri wkli comp win fa cup final tkt st m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go jurong point crazi avail bugi n great world...\n",
       "1   0                              ok lar joke wif u oni\n",
       "2   1  free entri wkli comp win fa cup final tkt st m...\n",
       "3   0                u dun say earli hor u c alreadi say\n",
       "4   0               nah think goe usf live around though"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.loc[:,'v1'].values\n",
    "x=df.loc[:,'v2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting textual data to numerical data\n",
    "vectorizer=TfidfVectorizer()\n",
    "vectorizer.fit(x)\n",
    "x=vectorizer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators={'lr':LogisticRegression(),'svc':SVC(),'rfc':RandomForestClassifier(),'xgc':XGBClassifier(),'adc':AdaBoostClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model LogisticRegression()\n",
      "accuracy score: 0.9504666188083274\n",
      "model SVC()\n",
      "accuracy score: 0.9720028715003589\n",
      "model RandomForestClassifier()\n",
      "accuracy score: 0.9770279971284996\n",
      "model XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "accuracy score: 0.9727207465900933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shish\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model AdaBoostClassifier()\n",
      "accuracy score: 0.9669777458722182\n"
     ]
    }
   ],
   "source": [
    "for name,model in estimators.items():\n",
    "    model.fit(x_train,y_train)\n",
    "    print(\"model\",model)\n",
    "    y_pred=model.predict(x_test)\n",
    "    score=accuracy_score(y_pred,y_test)\n",
    "    print(\"accuracy score:\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "\n",
    "    # Create the RandomForestClassifier with suggested hyperparameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Perform 3-fold cross-validation and calculate accuracy\n",
    "    score = cross_val_score(model, x_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 17:31:22,251] A new study created in memory with name: no-name-22ae8155-96d2-484b-b483-1b48a8e8871f\n",
      "[I 2025-03-05 17:31:22,800] Trial 0 finished with value: 0.8671931083991385 and parameters: {'n_estimators': 104, 'max_depth': 4}. Best is trial 0 with value: 0.8671931083991385.\n",
      "[I 2025-03-05 17:31:23,335] Trial 1 finished with value: 0.8801148600143575 and parameters: {'n_estimators': 68, 'max_depth': 7}. Best is trial 1 with value: 0.8801148600143575.\n",
      "[I 2025-03-05 17:31:24,133] Trial 2 finished with value: 0.893993778415889 and parameters: {'n_estimators': 89, 'max_depth': 9}. Best is trial 2 with value: 0.893993778415889.\n",
      "[I 2025-03-05 17:31:24,679] Trial 3 finished with value: 0.8904044029672171 and parameters: {'n_estimators': 61, 'max_depth': 9}. Best is trial 2 with value: 0.893993778415889.\n",
      "[I 2025-03-05 17:31:26,748] Trial 4 finished with value: 0.9514237855946398 and parameters: {'n_estimators': 118, 'max_depth': 20}. Best is trial 4 with value: 0.9514237855946398.\n",
      "[I 2025-03-05 17:31:27,581] Trial 5 finished with value: 0.8669538167025603 and parameters: {'n_estimators': 184, 'max_depth': 3}. Best is trial 4 with value: 0.9514237855946398.\n",
      "[I 2025-03-05 17:31:29,513] Trial 6 finished with value: 0.916487197894233 and parameters: {'n_estimators': 171, 'max_depth': 12}. Best is trial 4 with value: 0.9514237855946398.\n",
      "[I 2025-03-05 17:31:32,133] Trial 7 finished with value: 0.936587700406796 and parameters: {'n_estimators': 184, 'max_depth': 16}. Best is trial 4 with value: 0.9514237855946398.\n",
      "[I 2025-03-05 17:31:33,063] Trial 8 finished with value: 0.868150275185451 and parameters: {'n_estimators': 155, 'max_depth': 5}. Best is trial 4 with value: 0.9514237855946398.\n",
      "[I 2025-03-05 17:31:34,028] Trial 9 finished with value: 0.8731754008135918 and parameters: {'n_estimators': 144, 'max_depth': 6}. Best is trial 4 with value: 0.9514237855946398.\n",
      "[I 2025-03-05 17:31:36,236] Trial 10 finished with value: 0.9516630772912181 and parameters: {'n_estimators': 123, 'max_depth': 20}. Best is trial 10 with value: 0.9516630772912181.\n",
      "[I 2025-03-05 17:31:38,299] Trial 11 finished with value: 0.9475951184493897 and parameters: {'n_estimators': 123, 'max_depth': 19}. Best is trial 10 with value: 0.9516630772912181.\n",
      "[I 2025-03-05 17:31:40,361] Trial 12 finished with value: 0.9521416606843743 and parameters: {'n_estimators': 120, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:42,363] Trial 13 finished with value: 0.9375448671931084 and parameters: {'n_estimators': 140, 'max_depth': 16}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:43,832] Trial 14 finished with value: 0.9437664513041396 and parameters: {'n_estimators': 97, 'max_depth': 17}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:45,207] Trial 15 finished with value: 0.9246231155778895 and parameters: {'n_estimators': 114, 'max_depth': 13}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:46,556] Trial 16 finished with value: 0.9447236180904524 and parameters: {'n_estimators': 85, 'max_depth': 18}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:48,407] Trial 17 finished with value: 0.935151950227327 and parameters: {'n_estimators': 136, 'max_depth': 15}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:51,192] Trial 18 finished with value: 0.9511844938980617 and parameters: {'n_estimators': 163, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:53,707] Trial 19 finished with value: 0.927494615936827 and parameters: {'n_estimators': 200, 'max_depth': 14}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:54,880] Trial 20 finished with value: 0.9454414931801867 and parameters: {'n_estimators': 74, 'max_depth': 18}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:56,872] Trial 21 finished with value: 0.9507059105049055 and parameters: {'n_estimators': 117, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:31:59,110] Trial 22 finished with value: 0.9511844938980617 and parameters: {'n_estimators': 129, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:00,681] Trial 23 finished with value: 0.9475951184493899 and parameters: {'n_estimators': 98, 'max_depth': 18}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:02,323] Trial 24 finished with value: 0.9437664513041398 and parameters: {'n_estimators': 107, 'max_depth': 17}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:04,915] Trial 25 finished with value: 0.9478344101459678 and parameters: {'n_estimators': 153, 'max_depth': 19}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:06,165] Trial 26 finished with value: 0.9021296960995452 and parameters: {'n_estimators': 127, 'max_depth': 10}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:08,134] Trial 27 finished with value: 0.9507059105049055 and parameters: {'n_estimators': 113, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:09,322] Trial 28 finished with value: 0.9349126585307491 and parameters: {'n_estimators': 87, 'max_depth': 15}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:10,953] Trial 29 finished with value: 0.9437664513041398 and parameters: {'n_estimators': 104, 'max_depth': 17}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:13,078] Trial 30 finished with value: 0.9485522852357023 and parameters: {'n_estimators': 129, 'max_depth': 19}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:15,820] Trial 31 finished with value: 0.9519023689877962 and parameters: {'n_estimators': 155, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:18,334] Trial 32 finished with value: 0.9468772433596554 and parameters: {'n_estimators': 147, 'max_depth': 19}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:20,467] Trial 33 finished with value: 0.9440057430007179 and parameters: {'n_estimators': 134, 'max_depth': 18}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:22,555] Trial 34 finished with value: 0.9511844938980617 and parameters: {'n_estimators': 122, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:25,026] Trial 35 finished with value: 0.9418521177315148 and parameters: {'n_estimators': 165, 'max_depth': 17}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:25,451] Trial 36 finished with value: 0.8863364441253889 and parameters: {'n_estimators': 50, 'max_depth': 8}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:26,437] Trial 37 finished with value: 0.9097870303900456 and parameters: {'n_estimators': 95, 'max_depth': 11}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:29,013] Trial 38 finished with value: 0.9373055754965303 and parameters: {'n_estimators': 180, 'max_depth': 16}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:31,455] Trial 39 finished with value: 0.9471165350562335 and parameters: {'n_estimators': 150, 'max_depth': 19}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:32,882] Trial 40 finished with value: 0.9365877004067958 and parameters: {'n_estimators': 107, 'max_depth': 15}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:35,684] Trial 41 finished with value: 0.9514237855946398 and parameters: {'n_estimators': 164, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:38,345] Trial 42 finished with value: 0.9514237855946398 and parameters: {'n_estimators': 158, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:41,247] Trial 43 finished with value: 0.9478344101459678 and parameters: {'n_estimators': 179, 'max_depth': 19}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:42,032] Trial 44 finished with value: 0.8669538167025603 and parameters: {'n_estimators': 172, 'max_depth': 3}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:45,056] Trial 45 finished with value: 0.9449629097870303 and parameters: {'n_estimators': 195, 'max_depth': 18}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:47,283] Trial 46 finished with value: 0.9475951184493899 and parameters: {'n_estimators': 137, 'max_depth': 19}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:49,770] Trial 47 finished with value: 0.9514237855946398 and parameters: {'n_estimators': 143, 'max_depth': 20}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:51,465] Trial 48 finished with value: 0.938741325675999 and parameters: {'n_estimators': 119, 'max_depth': 16}. Best is trial 12 with value: 0.9521416606843743.\n",
      "[I 2025-03-05 17:32:53,988] Trial 49 finished with value: 0.9437664513041396 and parameters: {'n_estimators': 162, 'max_depth': 18}. Best is trial 12 with value: 0.9521416606843743.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())  # We aim to maximize accuracy\n",
    "study.optimize(objective, n_trials=50)  # Run 50 trials to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763101220387652"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(x_train,y_train)\n",
    "y_pred=rfc.predict(x_test)\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rfc,open(\"rfc.pkl\",\"wb\"))\n",
    "pickle.dump(vectorizer,open(\"tfd.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "rfc = pickle.load(open('rfc.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(text):\n",
    "    test=streming(text)\n",
    "    test=np.array([test])\n",
    "    test=vectorizer.transform(test)\n",
    "    pred=rfc.predict(test)\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"hello my name is google and im here to inform you about your placements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'hello im a fish'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rfc\u001b[38;5;241m.\u001b[39mpredict([[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello im a fish\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\shish\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shish\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\shish\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\shish\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shish\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'hello im a fish'"
     ]
    }
   ],
   "source": [
    "rfc.predict([['hello im a fish']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
